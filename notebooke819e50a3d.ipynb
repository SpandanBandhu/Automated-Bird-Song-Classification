{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7834035,"sourceType":"datasetVersion","datasetId":4591715}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport librosa\nfrom glob import glob\nimport IPython.display as ipd\nimport tensorflow as tf\nfrom PIL import Image","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-03-13T15:00:35.766846Z","iopub.execute_input":"2024-03-13T15:00:35.767122Z","iopub.status.idle":"2024-03-13T15:00:50.183288Z","shell.execute_reply.started":"2024-03-13T15:00:35.767098Z","shell.execute_reply":"2024-03-13T15:00:50.182497Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-13 15:00:39.015066: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-13 15:00:39.015148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-13 15:00:39.181985: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/british-bird-song-dataset/BRITISH BIRD SONG METADATA - birdsong_metadata.csv\")\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:01:16.357781Z","iopub.execute_input":"2024-03-13T15:01:16.358511Z","iopub.status.idle":"2024-03-13T15:01:16.509435Z","shell.execute_reply.started":"2024-03-13T15:01:16.358479Z","shell.execute_reply":"2024-03-13T15:01:16.508044Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/british-bird-song-dataset/BRITISH BIRD SONG METADATA - birdsong_metadata.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/british-bird-song-dataset/BRITISH BIRD SONG METADATA - birdsong_metadata.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/british-bird-song-dataset/BRITISH BIRD SONG METADATA - birdsong_metadata.csv'","output_type":"error"}]},{"cell_type":"code","source":"class_names = df[\"species\"].unique()\nprint(class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"species\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 25))\nax.barh(df[\"species\"].unique(), df[\"species\"].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting all the WAV files","metadata":{}},{"cell_type":"code","source":"path_to_flac = \"/kaggle/input/british-bird-song-dataset/songs/songs\"\ndatafiles = glob(path_to_flac + \"*\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to generate a spectrogram","metadata":{}},{"cell_type":"code","source":"import librosa\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport librosa.display\nimport IPython.display as ipd\n\ndef generate_spectrogram(file_audio, identifier,):\n    audio_data, sample_rate = librosa.load(path_to_flac + \"/\" + file_audio)\n    spec_mel = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n    spec_mel = librosa.power_to_db(spec_mel, ref=np.max)\n    figure, axis = plt.subplots(figsize=(15, 5))\n    axis.set_title(\"Mel Spectrogram\")\n    plt.suptitle(identifier)\n    librosa.display.specshow(spec_mel, x_axis='time', y_axis='log', ax=axis)\n    return ipd.Audio(path_to_flac + \"/\" + file_audio, rate=sample_rate)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating random spectrogram","metadata":{}},{"cell_type":"code","source":"i = np.random.randint(0, df.shape[0])\ngenerate_spectrogram(df.loc[i, \"file_id\"], df.loc[i, \"species\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport librosa\nimport matplotlib.pyplot as plt\n\n# Path to the directory containing FLAC files\ndirectory = '/kaggle/input/british-bird-song-dataset/songs/songs'\n\n# Iterate over each file in the directory\nfor filename in os.listdir(directory):\n    if filename.endswith(\".flac\"):\n        filepath = os.path.join(directory, filename)\n        \n        # Load the audio file\n        y, sr = librosa.load(filepath)\n        \n        # Create and plot the spectrogram\n        plt.figure(figsize=(10, 4))\n        spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n        librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n        plt.colorbar(format='%+2.0f dB')\n        plt.title('Spectrogram for {}'.format(filename))\n        plt.show()\n\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting waveform","metadata":{}},{"cell_type":"code","source":"filename = \"/kaggle/input/british-bird-song-dataset/songs/songs/xc101936.flac\"\naudio_data, sample_rate = librosa.load(filename)\n\nplt.plot(audio_data)\nplt.title(\"Waveform\")\nplt.xlabel(\"Sample\")\nplt.ylabel(\"Amplitude\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename =\"/kaggle/input/british-bird-song-dataset/songs/songs/xc101936.flac\"\naudio_data, sample_rate = librosa.load(filename)\nspectrogram = librosa.stft(audio_data)\nspectrogram = np.abs(spectrogram)\n\nplt.imshow(spectrogram, origin='lower', aspect='auto')\n#plt.title(\"Spectrogram\")\nplt.xlabel(\"Time (samples)\")\nplt.ylabel(\"Frequency\")\nplt.colorbar()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing function for audio","metadata":{}},{"cell_type":"code","source":"def process_audio(audio_file):\n    audio_data, sample_rate = librosa.load(audio_file, duration=10)\n    mel_spec = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate) \n    mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n    return mel_spec","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = '/kaggle/input/british-bird-song-dataset/songs/songs/xc101940.flac'\nprint(len(process_audio(filename)))\nprint(len(process_audio(filename)[0]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating a pandas Dataframe to process the data from the CSV and wav files","metadata":{}},{"cell_type":"code","source":"df_train = pd.DataFrame({\"species\": df[\"species\"], \"audiopath\": path_to_flac +\"/\"+ df[\"file_id\"]})\n\n# Assuming `process_audio` is a function that generates mel spectrograms\ndf_train[\"mel_spec\"] = df_train[\"audiopath\"].apply(lambda x: process_audio(x))\n\n# Using factorize to encode class labels\ndf_train[\"class\"] = df_train[\"species\"].factorize()[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Shuffle data","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndf_train = shuffle(df_train)\ndf_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seperate train and test data","metadata":{}},{"cell_type":"code","source":"(train_x, train_y) = df_train[\"mel_spec\"][:100].values, df_train[\"class\"][:100].values\n(test_x, test_y) = df_train[\"mel_spec\"][100:].values, df_train[\"class\"][100:].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\n\ntest_y = to_categorical(test_y, num_classes=len(class_names))\ntrain_y = to_categorical(train_y, num_classes=len(class_names))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Normalize data and generate Tensorflow datasets","metadata":{}},{"cell_type":"code","source":"train_x = np.stack(train_x[:])\ntest_x = np.stack(test_x[:])\n\ntrain_x = tf.keras.utils.normalize(train_x)\ntest_x = tf.keras.utils.normalize(test_x)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom skimage.transform import resize\n\n# Assuming all spectrograms should be of size (128, 128)\ndesired_shape = (128, 128)\n\n# Resize each spectrogram to the desired shape\ntrain_x_resized = [resize(spec, desired_shape) for spec in train_x]\ntest_x_resized = [resize(spec, desired_shape) for spec in test_x]\n\n# Stack the resized spectrograms\ntrain_x_stacked = np.stack(train_x_resized)\ntest_x_stacked = np.stack(test_x_resized)\n\n# Now, normalize the data as before\ntrain_x_normalized = tf.keras.utils.normalize(train_x_stacked)\ntest_x_normalized = tf.keras.utils.normalize(test_x_stacked)\n\n# Then, create the datasets as before\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_x_normalized, train_y))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_x_normalized, test_y))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setting batch sizes","metadata":{}},{"cell_type":"code","source":"train_dataset = train_dataset.batch(10)\ntest_dataset = test_dataset.batch(10)\ntrain_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\ntest_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Reshape, InputLayer, Dropout\nfrom keras.applications import InceptionResNetV2\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import layers\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setting up model","metadata":{}},{"cell_type":"code","source":"model = keras.models.Sequential()\n# def stem(inputs):\n#model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(128, 130))\n\n\nmodel.add(InputLayer(input_shape=(128,431)))\nmodel.add(Reshape((128,431,1)))\nmodel.add(Conv2D(32, (8, 8), input_shape=(128, 431,1), activation='relu'))\nmodel.add(Conv2D(32, (8,8), activation='relu'))\nmodel.add(Conv2D(64, (8,8), activation='relu'))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Conv2D(16, (2,2), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(85, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model2 = keras.models.Sequential()\n\n# model2.add(InputLayer(input_shape=(128,130)))\n# model2.add(Reshape((128,130,1)))\n# model2.add(Conv2D(64, (8, 8), input_shape=(128, 130), activation='relu'))\n# model2.add(BatchNormalization())\n# model2.add(MaxPooling2D(pool_size=(2,2)))\n# model2.add(Conv2D(16, (2,2), activation='relu'))\n# model2.add(Flatten())\n# model2.add(Dropout(0.5))\n# model2.add(Dense(128, activation='relu'))\n# model2.add(Dense(5, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model3 = keras.models.Sequential()\n\n# model3.add(InputLayer(input_shape=(128,130)))\n# model3.add(Reshape((128,130,1)))\n# model3.add(Conv2D(64, (8, 8), input_shape=(128, 130), activation='relu'))\n# model3.add(BatchNormalization())\n# model3.add(MaxPooling2D(pool_size=(2,2)))\n# model3.add(Conv2D(16, (2,2), activation='relu'))\n# model3.add(Flatten())\n# model3.add(Dropout(0.5))\n# model3.add(Dense(128, activation='relu'))\n# model3.add(Dense(5, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model compiling","metadata":{}},{"cell_type":"code","source":"model.compile('adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision(), 'accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model2.compile('adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision(), 'accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model3.compile('adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision(), 'accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model training","metadata":{}},{"cell_type":"code","source":"hist = model.fit(train_dataset, epochs=20, validation_data=test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hist2 = model2.fit(train_dataset, epochs=50, validation_data=test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hist3 = model3.fit(train_dataset, epochs=20, validation_data=test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model evaluation on accuracy on test dataset","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model2.evaluate(test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model3.evaluate(test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(test_x) \ny_pred=np.argmax(y_pred, axis=1)\ny_test=np.argmax(test_y, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_pred)\nprint(y_test)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, \n            annot=True,\n            fmt='g', \n            xticklabels=[\"Bewick's Wren\",\"Northern Mockingbird\",\"American Robin\",\"Song Sparrow\",\"Northern Cardinal\"],\n            yticklabels=[\"Bewick's Wren\",\"Northern Mockingbird\",\"American Robin\",\"Song Sparrow\",\"Northern Cardinal\"])\nplt.ylabel('Prediction',fontsize=13)\nplt.xlabel('Actual',fontsize=13)\nplt.title('Confusion Matrix',fontsize=17)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_accuracy = hist.history['accuracy']\nval_accuracy = hist.history['val_accuracy']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(train_loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(train_accuracy, label='Training Accuracy')\nplt.plot(val_accuracy, label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lots of plots","metadata":{}},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(hist.history['loss'], 'r', label='Overall Loss')\nplt.plot(hist.history['val_loss'], 'b', label='Loss Value per Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Value')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.title('Loss')\n# plt.plot(hist.history['loss'], 'r', label='Loss for 100 Epoch model')\n# plt.plot(hist2.history['loss'], 'b', label='Loss for 50 Epoch model')\n# plt.plot(hist3.history['loss'], 'g', label='Loss for 20 Epoch model')\n# plt.xlabel('Epoch')\n# plt.ylabel('Value')\n# plt.legend()\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Precision')\nplt.plot(hist.history['precision_13'], 'r', label='Overall Precision')\nplt.plot(hist.history['val_precision_13'], 'b', label='Precision Value per Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Value')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Recall')\nplt.plot(hist.history['recall_13'], 'r', label='Overall Recall')\nplt.plot(hist.history['val_recall_13'], 'b', label='Recall Value per Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Value')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Accuracy')\nplt.plot(hist.history['accuracy'], 'r', label='Overall Accuracy')\nplt.plot(hist.history['val_accuracy'], 'b', label='Accuracy Value per Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Value')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_file = '/kaggle/input/bird-song-data-set/wavfiles/101308-9.wav'\naudio_data, sample_rate = librosa.load(audio_file, duration=3)\nmel_spec = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate) \nmel_spec = librosa.power_to_db(mel_spec, ref=np.max)\nmel_spec = tf.expand_dims(mel_spec, axis=0)\nbird_list = [\"Bewick's Wren\", \"Northern Mockingbird\", \"American Robin\", \"Song Sparrow\", \"Northern Cardinal\"]\n\ntest=model.predict(mel_spec)\n\nprint(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('my_model.h5')\n\n# Download the model file\nimport shutil\nshutil.move('my_model.h5', '/kaggle/working/my_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate model file for easy usage later","metadata":{}},{"cell_type":"code","source":"# from IPython.display import FileLink\n\n# model.save(\"saved_model\") \n# !zip -r saved_model.zip './saved_model' \n# FileLink(r'./saved_model.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}